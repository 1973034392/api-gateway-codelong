# 24 并发编程问题

## 119. 线程安全的集合

### 系统中使用了哪些线程安全的集合？
1) **ConcurrentHashMap**：用于缓存Dubbo服务引用（`dubboServiceMap`）、服务超时配置（`serviceTimeoutCache`）、响应缓存（`responseCache`）、网关实例（`NginxConfUtil.instances`）；

2) **Cache（Hutool）**：用于缓存接口配置（`httpStatementMap`），底层使用ConcurrentHashMap；

3) **CopyOnWriteArrayList**：可用于存储自定义处理器列表，读多写少场景；

4) **ArrayBlockingQueue**：用于线程池的工作队列。

### CopyOnWriteArrayList的优缺点是什么？
**优点**：

1) **读操作无锁**：读操作不加锁，性能极高；

2) **线程安全**：写操作通过复制数组保证线程安全；

3) **迭代安全**：迭代过程中不会抛出`ConcurrentModificationException`。


**缺点**：

1) **内存开销**：每次写操作都复制整个数组，内存占用大；

2) **写性能差**：写操作需要复制数组，性能较差；

3) **数据一致性**：读操作可能读到旧数据。


**适用场景**：读多写少，如配置列表、监听器列表。

### ConcurrentHashMap的实现原理是什么？
JDK 1.8+实现：

1) **数组+链表+红黑树**：底层结构与HashMap相同；

2) **CAS+synchronized**：使用CAS操作和synchronized锁桶头节点，锁粒度更细；

3) **分段锁思想**：每个桶独立加锁，不同桶可并发操作；

4) **扩容优化**：支持多线程协助扩容，提高扩容效率；

5) **size计算**：使用`CounterCell`数组累加，避免全局锁。相比JDK 1.7的Segment分段锁，1.8+并发度更高。

### 如何选择合适的线程安全集合？
1) **读多写少**：使用`CopyOnWriteArrayList`或`CopyOnWriteArraySet`；

2) **高并发读写**：使用`ConcurrentHashMap`；

3) **有序集合**：使用`ConcurrentSkipListMap`（跳表实现）；

4) **队列**：使用`ConcurrentLinkedQueue`（无界）或`ArrayBlockingQueue`（有界）；

5) **栈**：使用`ConcurrentLinkedDeque`。项目中主要使用`ConcurrentHashMap`，因为需要高并发读写缓存。

## 120. 原子操作

### 系统中使用了哪些原子操作？
虽然项目代码中未显式使用原子类，但可在以下场景使用：

1) **请求计数**：使用`AtomicLong`统计总请求数；

2) **限流计数**：使用`AtomicInteger`统计当前并发数；

3) **错误计数**：使用`AtomicInteger`统计错误次数；

4) **状态标记**：使用`AtomicBoolean`标记服务状态；

5) **版本号**：使用`AtomicInteger`实现乐观锁版本号。

### AtomicInteger的实现原理是什么？
基于CAS（Compare-And-Swap）实现：

1) **Unsafe类**：通过`Unsafe.compareAndSwapInt()`实现原子操作；

2) **自旋重试**：CAS失败时自旋重试直到成功；

3) **volatile变量**：value字段使用volatile保证可见性；

4) **无锁算法**：不使用锁，通过硬件指令保证原子性；

5) **ABA问题**：可能存在ABA问题，可使用`AtomicStampedReference`解决。性能优于synchronized，适合高并发场景。

### 如何使用原子操作实现计数器？
```java
public class RequestCounter {
    private final AtomicLong totalCount = new AtomicLong(0);
    private final AtomicLong successCount = new AtomicLong(0);
    private final AtomicLong errorCount = new AtomicLong(0);

    public void incrementTotal() {
        totalCount.incrementAndGet();
    }

    public void incrementSuccess() {
        successCount.incrementAndGet();
    }

    public void incrementError() {
        errorCount.incrementAndGet();
    }

    public long getErrorRate() {
        long total = totalCount.get();
        return total == 0 ? 0 : errorCount.get() * 100 / total;
    }
}
```

### 原子操作的性能如何？
1) **高并发优势**：在高并发场景下，原子操作性能优于synchronized，因为无需线程阻塞和上下文切换；

2) **低竞争劣势**：在低竞争场景下，synchronized经过JVM优化（偏向锁、轻量级锁）性能接近原子操作；

3) **自旋开销**：CAS失败时自旋重试会消耗CPU；

4) **适用场景**：适合简单的原子操作（如计数、状态切换），不适合复杂的复合操作；

5) **性能数据**：单线程下原子操作略慢于普通操作，多线程下性能优势明显。

## 121. 锁的使用

### 系统中使用了哪些锁？
1) **ReentrantLock**：`NginxConfUtil.refreshLock`用于同步Nginx配置刷新；

2) **synchronized**：`HTTPExecutorSpiFinder.getInstance()`使用类锁实现单例；

3) **CAS锁**：`ConcurrentHashMap`内部使用CAS+synchronized；

4) **分布式锁**：可使用Redis实现分布式锁控制配置更新；

5) **读写锁**：可使用`ReentrantReadWriteLock`优化缓存读写。

### ReentrantLock与synchronized的区别是什么？
1) **灵活性**：ReentrantLock支持公平锁、可中断、超时获取锁，synchronized不支持；

2) **性能**：JDK 1.6+优化后，两者性能接近；

3) **使用方式**：ReentrantLock需要手动释放锁（finally块），synchronized自动释放；

4) **条件变量**：ReentrantLock支持多个Condition，synchronized只有一个wait/notify；

5) **可重入**：两者都支持可重入。项目中`NginxConfUtil`使用ReentrantLock是因为需要tryLock()避免阻塞。

### 如何避免死锁？
1) **锁顺序**：多个锁按固定顺序获取，避免循环等待；

2) **超时机制**：使用`tryLock(timeout)`设置超时，获取失败时释放已持有的锁；

3) **避免嵌套锁**：尽量避免在持有锁时获取其他锁；

4) **使用并发工具**：使用`ConcurrentHashMap`等无锁数据结构；

5) **死锁检测**：使用JConsole、VisualVM等工具检测死锁。项目中锁使用较少，基本不会出现死锁。

### 如何监控锁的竞争情况？
1) **JMX监控**：通过JMX获取锁的等待时间、持有时间；

2) **日志记录**：在获取锁前后记录日志，分析锁持有时间；

3) **性能分析工具**：使用JProfiler、YourKit等工具分析锁竞争；

4) **自定义指标**：记录锁获取失败次数、等待时间等指标；

5) **告警机制**：锁等待时间超过阈值时告警。可在`NginxConfUtil.refreshLock`周围添加监控代码。

## 122. 线程池的使用

### 系统中使用了哪些线程池？
1) **ExecutorHandler线程池**：自定义线程池处理请求，核心线程数=CPU核心数×2，最大线程数=CPU核心数×4；

2) **Netty EventLoopGroup**：boss线程池（1个线程）接收连接，worker线程池（4个线程）处理I/O；

3) **定时线程池**：用于心跳续约、连接清理等定时任务；

4) **HTTP异步客户端线程池**：Apache HttpAsyncClient内部的I/O线程池；

5) **Spring异步线程池**：处理Redis消息监听等异步任务。

### 如何配置线程池的参数？
`ExecutorHandler`线程池配置：

```java
new ThreadPoolExecutor(
    Runtime.getRuntime().availableProcessors() * 2,  // 核心线程数
    Runtime.getRuntime().availableProcessors() * 4,  // 最大线程数
    60L, TimeUnit.SECONDS,                           // 空闲线程存活时间
    new ArrayBlockingQueue<>(1000),                  // 工作队列
    new ThreadPoolExecutor.CallerRunsPolicy()        // 拒绝策略
)
```


**配置原则**：

1) **CPU密集型**：核心线程数=CPU核心数+1；

2) **I/O密集型**：核心线程数=CPU核心数×2；

3) **队列大小**：根据内存和任务特性设置；

4) **拒绝策略**：根据业务选择。

### 如何监控线程池的使用情况？
1) **线程池指标**：监控活跃线程数、队列大小、完成任务数、拒绝任务数；

2) **JMX监控**：通过`ThreadPoolExecutor`的getter方法获取指标；

3) **自定义监控**：定时打印线程池状态：`log.info("线程池状态: active={}, queue={}", executor.getActiveCount(), executor.getQueue().size())`；

4) **告警**：队列满或拒绝任务时告警；

5) **可视化**：将指标上报到Prometheus+Grafana展示。

### 如何处理线程池的拒绝策略？
项目使用`CallerRunsPolicy`：

1) **CallerRunsPolicy**：调用者线程执行任务，提供降级但可能阻塞调用者；

2) **AbortPolicy**：抛出异常，适合不允许丢失任务的场景；

3) **DiscardPolicy**：静默丢弃任务，适合允许丢失的场景；

4) **DiscardOldestPolicy**：丢弃最老的任务，适合优先处理新任务的场景；

5) **自定义策略**：记录日志、上报监控、降级处理等。选择`CallerRunsPolicy`是因为网关不能丢失请求，宁可降低吞吐也要保证处理。

## 123. 异步编程的陷阱

### 异步编程中有哪些常见的陷阱？
1) **异常丢失**：异步任务中的异常未捕获会被吞掉；

2) **上下文丢失**：ThreadLocal、TraceId等上下文在异步任务中丢失；

3) **回调地狱**：多层嵌套回调导致代码难以维护；

4) **资源泄漏**：异步任务未正确释放资源（如连接、文件）；

5) **死锁**：异步任务间相互等待导致死锁；

6) **内存泄漏**：CompletableFuture未完成导致内存泄漏。

### 如何避免回调地狱？
项目使用CompletableFuture链式调用：

```java
connection.send(parameters, httpStatement)
    .thenAccept(result -> {
        channel.attr(AttributeKey.valueOf("data")).set(result);
        ctx.fireChannelRead(request);
    })
    .exceptionally(throwable -> {
        log.error("服务调用失败", throwable);
        sendError(channel, "服务调用失败");
        return null;
    });
```

**避免方法**：

1) **链式调用**：使用`thenApply()`、`thenCompose()`等方法；

2) **提取方法**：将回调逻辑提取为独立方法；

3) **async/await**：Java不支持，但可使用Kotlin协程；

4) **响应式编程**：使用Reactor、RxJava等框架。

### 如何处理异步异常？
1) **exceptionally()**：捕获异常并返回默认值：`future.exceptionally(e -> defaultValue)`；

2) **handle()**：同时处理成功和失败：`future.handle((result, ex) -> ex == null ? result : defaultValue)`；

3) **whenComplete()**：无论成功失败都执行：`future.whenComplete((result, ex) -> cleanup())`；

4) **全局异常处理**：设置默认异常处理器；

5) **日志记录**：所有异常都记录日志。项目中使用`exceptionally()`捕获异常并返回错误Result。

### 如何调试异步代码？
1) **日志追踪**：在异步任务开始和结束处打印日志，包含TraceId；

2) **断点调试**：在IDE中设置断点，注意异步任务在不同线程执行；

3) **线程名**：为线程池设置有意义的线程名，便于识别；

4) **堆栈追踪**：异常堆栈可能不完整，需要在任务提交处记录堆栈；

5) **监控工具**：使用APM工具（如SkyWalking）追踪异步调用链。

## 124. 内存可见性

### 什么是内存可见性？
内存可见性是指一个线程修改的共享变量，其他线程能否立即看到修改后的值。由于CPU缓存和编译器优化，线程可能读取到旧值。例如：线程A修改`flag=true`，线程B可能仍然读到`flag=false`。Java内存模型（JMM）定义了happens-before规则保证可见性。

### volatile关键字的作用是什么？
1) **保证可见性**：volatile变量的写操作会立即刷新到主内存，读操作从主内存读取；

2) **禁止重排序**：volatile变量的读写操作不会被重排序；

3) **不保证原子性**：`i++`等复合操作不是原子的；

4) **轻量级同步**：性能优于synchronized；

5) **使用场景**：状态标记、双重检查锁的单例。项目中`HTTPExecutorSpiFinder.executor`使用volatile保证可见性。

### 如何保证内存的可见性？
1) **volatile**：对于单个变量的读写；

2) **synchronized**：同步块内的变量修改对其他线程可见；

3) **Lock**：ReentrantLock等显式锁；

4) **final**：final字段在构造函数完成后对其他线程可见；

5) **Atomic类**：原子类内部使用volatile；

6) **happens-before规则**：利用JMM的happens-before规则。项目中主要使用volatile和ConcurrentHashMap保证可见性。

### 内存可见性对性能的影响有多大？
1) **volatile开销**：volatile读操作几乎无开销，写操作需要刷新缓存，性能略低于普通变量；

2) **缓存失效**：volatile写操作会导致其他CPU缓存失效，影响性能；

3) **内存屏障**：volatile会插入内存屏障，禁止重排序；

4) **权衡**：在正确性和性能间权衡，优先保证正确性；

5) **优化**：减少volatile变量的写操作，批量更新后再写入。在网关场景下，volatile开销可忽略。

## 125. 指令重排序

### 什么是指令重排序？
指令重排序是编译器和CPU为了优化性能，在不改变单线程执行结果的前提下，调整指令执行顺序。例如：

```java
int a = 1;  // 1
int b = 2;  // 2
int c = a + b;  // 3
```

指令1和2可能被重排序为2、1，但3不会排到1、2之前。在多线程环境下，重排序可能导致可见性问题。

### 指令重排序对并发编程的影响是什么？
经典案例是双重检查锁的单例模式：

```java
if (instance == null) {
    synchronized (Singleton.class) {
        if (instance == null) {
            instance = new Singleton();  // 可能重排序
        }
    }
}
````

`new Singleton()`分为3步：

1) 分配内存；

2) 初始化对象；

3) 将引用指向内存。如果2和3重排序，其他线程可能看到未初始化的对象。解决方法：使用volatile修饰instance。

### 如何避免指令重排序的问题？
1) **volatile**：禁止volatile变量前后的指令重排序；

2) **synchronized**：同步块内的指令不会重排序到同步块外；

3) **final**：final字段的初始化不会重排序到构造函数外；

4) **happens-before规则**：利用JMM的happens-before规则；

5) **内存屏障**：显式插入内存屏障（较少使用）。项目中使用volatile保证单例的正确性。

### 内存屏障的作用是什么？
内存屏障是CPU指令，用于控制内存访问顺序：

1) **LoadLoad屏障**：禁止Load指令重排序；

2) **StoreStore屏障**：禁止Store指令重排序；

3) **LoadStore屏障**：禁止Load和Store重排序；

4) **StoreLoad屏障**：禁止Store和Load重排序，开销最大；

5) **volatile语义**：volatile写插入StoreStore+StoreLoad屏障，volatile读插入LoadLoad+LoadStore屏障。Java开发者通常不直接使用内存屏障，而是通过volatile、synchronized等关键字。

