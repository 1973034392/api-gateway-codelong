# 01 项目整体架构与设计

## 1. 项目整体架构设计

### 请描述这个网关系统的整体架构设计，包括各个模块之间的关系
**五大核心模块**：
1. **网关核心服务(api-gateway-core)**：基于Netty的请求处理核心，负责请求接入、鉴权、限流、路由、协议转换、服务调用
2. **网关中心(api-gateway-center)**：配置管理中心，负责服务注册发现、接口信息管理、限流配置、Nginx配置动态刷新
3. **服务注册SDK(server-find-sdk)**：服务提供者使用，自动扫描注解并注册接口信息，维持心跳
4. **服务调用SDK(server-send-sdk)**：简化HTTP/RPC调用，支持失败重试
5. **Redis**：作为注册中心存储接口信息、心跳状态，作为消息队列实现配置同步

**模块关系**：服务提供者通过注册SDK向网关中心注册 → 网关中心将配置同步到Redis和Nginx → 网关核心从Redis拉取配置 → 客户端请求经Nginx负载均衡到网关核心 → 网关核心根据配置路由到服务提供者

### 为什么选择使用Netty而不是Spring WebFlux或其他框架？
1. **性能极致**：Netty基于NIO，零拷贝、直接内存、对象池等优化，QPS比WebFlux高30%+
2. **精细控制**：可自定义线程模型、内存管理、编解码器，满足网关对性能的极致要求
3. **成熟稳定**：经过大规模生产验证，Dubbo、RocketMQ等都基于Netty
4. **责任链天然支持**：ChannelPipeline天然支持责任链模式，适合网关多阶段处理

### 系统中有哪些核心模块？各模块的职责是什么？
1. **网络通信层**：SocketServerBootStrap启动Netty服务，ServerHandlerInitializer初始化处理器链
2. **请求处理链**：AuthorizationHandler(鉴权) → PreExecutorHandler(前置处理/限流) → ExecutorHandler(服务调用) → PostExecutorHandler(后置处理) → ResultHandler(结果封装)
3. **协议支持层**：HTTPConnection/DubboConnection封装协议调用，DefaultHTTPExecutor/DefaultDubboExecutor执行异步调用
4. **配置管理**：GlobalConfiguration全局配置中心，InterfaceCacheUtil多级缓存(L1内存+L2 Redis)
5. **服务治理**：GatewayServer负载均衡，RedisMessageListener配置同步，心跳续约机制

### 如何理解"责任链模式"在这个项目中的应用？
**Netty Pipeline责任链**：请求依次经过5个Handler，每个Handler处理完调用`ctx.fireChannelRead()`传递给下一个，任一Handler可中断链路直接返回响应

**自定义处理器责任链**：PreExecutorHandler和PostExecutorHandler内部维护自定义处理器列表，按Order排序执行。前置处理器可实现限流、黑白名单等，返回非null结果则中断；后置处理器用于日志、监控等

**优势**：解耦各处理阶段，易扩展新功能，支持动态调整处理顺序

## 2. 项目的核心特性

### 这个网关系统支持哪些协议？如何实现多协议支持的？
**支持协议**：HTTP、Dubbo

**实现方式**：
1. **统一抽象**：BaseConnection接口统一调用入口，返回CompletableFuture异步结果
2. **协议路由**：ExecutorHandler根据HttpStatement.isHttp字段判断协议类型
3. **HTTP调用**：HTTPConnection使用Apache HttpAsyncClient异步发送请求
4. **Dubbo调用**：DubboConnection使用泛化调用`$invokeAsync`，无需依赖服务接口
5. **扩展性**：新增协议只需实现BaseConnection接口

### 系统如何实现高并发处理？采用了哪些性能优化策略？
1. **Netty NIO**：主从Reactor模型，boss线程接收连接，worker线程处理请求，非阻塞IO
2. **异步化**：HTTP使用HttpAsyncClient，Dubbo使用$invokeAsync，CompletableFuture链式处理，不阻塞Netty线程
3. **连接池复用**：HTTP连接池(最大500连接)，Dubbo服务引用缓存，避免重复创建
4. **多级缓存**：L1内存缓存(LRU)+L2 Redis缓存，接口配置和响应数据缓存，Redis Pub/Sub保证一致性
5. **零拷贝**：Netty DirectBuffer直接内存，减少内存拷贝
6. **对象池**：请求对象复用，减少GC压力
7. **分布式限流**：本地限流(Guava RateLimiter)+Redis分布式限流，支持全局/服务/接口/IP四级限流

### 请解释什么是"分布式服务治理"，在这个项目中如何体现的？
**分布式服务治理**：对分布式系统中的服务进行统一管理，包括服务注册发现、负载均衡、限流降级、配置管理、监控告警等

**本项目体现**：
1. **服务注册发现**：服务提供者通过SDK注册到网关中心，信息存储到Redis，心跳续约(15s间隔，30s过期)，自动下线
2. **负载均衡**：Nginx一级负载均衡+网关核心二级负载均衡(权重轮询)
3. **分布式限流**：支持全局/服务/接口/IP四级限流，令牌桶+滑动窗口算法，配置实时推送
4. **配置管理**：网关中心统一管理配置，通过Redis Pub/Sub实时推送到所有网关节点
5. **熔断降级**：自定义前置处理器实现熔断检查，返回降级响应

### 系统的可扩展性如何？如何添加新的功能模块？
**扩展点**：
1. **自定义处理器**：实现CustomPreHandler/CustomPostHandler接口，通过@Order控制执行顺序，Spring自动扫描加载
2. **协议扩展**：实现BaseConnection和BaseExecutor接口，支持gRPC等新协议
3. **限流算法扩展**：实现RateLimiter接口，添加新的限流算法
4. **SPI机制**：HTTPExecutor通过SPI加载，支持自定义实现
5. **插件式设计**：各模块通过接口解耦，易于替换和扩展

## 3. 技术栈选择

### 为什么选择Redis作为缓存和消息队列？
1. **高性能**：内存存储，QPS可达10万+，满足网关高并发需求
2. **多功能**：支持缓存(String/Hash)、消息队列(Pub/Sub)、分布式锁、过期机制
3. **过期机制**：利用Key过期实现心跳续约，自动下线失效服务
4. **Pub/Sub**：实现配置实时推送，保证多网关节点配置一致性
5. **轻量级**：相比Kafka/RabbitMQ更轻量，适合配置同步场景

### 为什么使用Dubbo而不是gRPC或其他RPC框架？
1. **泛化调用**：网关无需依赖服务接口，通过泛化调用动态调用任意Dubbo服务
2. **生态成熟**：国内广泛使用，与Spring集成完善
3. **异步支持**：$invokeAsync原生支持异步调用，返回CompletableFuture
4. **服务治理**：内置负载均衡、服务发现、容错机制
5. **性能优良**：基于Netty，支持多种序列化协议

### 为什么选择JWT进行身份认证？
1. **无状态**：Token自包含用户信息，网关无需存储Session，易于水平扩展
2. **跨域支持**：适合分布式系统，Token可在多个服务间传递
3. **防篡改**：通过签名验证Token完整性，结合安全组密钥双重校验
4. **性能高**：本地验证，无需查询数据库或Redis
5. **标准化**：业界标准，库支持完善

### 为什么使用Snowflake算法生成唯一ID？
1. **高性能**：本地生成，无需网络调用，QPS可达百万级
2. **全局唯一**：通过机器ID+时间戳+序列号保证唯一性
3. **趋势递增**：ID按时间递增，适合数据库索引
4. **信息可读**：ID包含时间戳，可反推生成时间
5. **分布式友好**：不同机器生成的ID不冲突

