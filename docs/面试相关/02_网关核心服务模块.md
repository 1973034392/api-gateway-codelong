# 02 网关核心服务模块

## 4. 全局配置管理

### GlobalConfiguration类的作用是什么？
`GlobalConfiguration`是网关核心的配置中心，负责：

1) 加载application.yml中的配置参数；
2) 初始化HTTP异步客户端连接池；
3) 创建LFU缓存用于存储HTTP请求声明；
4) 向网关中心注册服务并获取安全凭证；

5) 管理Dubbo服务缓存。

### 如何在应用启动时初始化全局配置？
通过`@PostConstruct`注解的`init()`方法在Bean初始化后执行：

1) 创建LFU缓存；
2) 调用`register()`向网关中心注册服务；
3) 创建异步HTTP客户端；
4) 启动连接回收线程。注册时获取`serverName`、`safeKey`、`safeSecret`等信息。

### 配置文件中的各个参数分别控制什么？
- `netty-port`: Netty服务监听端口（默认8888）
- `gateway-center`: 网关中心地址，用于服务注册和配置同步
- `group-key`: 网关分组标识，用于启动时获取配置
- `weight`: 服务权重（1-100），用于负载均衡
- `max-cache`: HTTP请求声明缓存最大数量（默认1000）
- `boss-threads`: Netty boss线程数（接收连接）
- `worker-threads`: Netty worker线程数（处理连接）

### 如何实现配置的热更新？
通过Redis Pub/Sub机制实现：

1) 网关中心修改配置后发布消息到Redis频道；
2) 网关核心监听对应频道；
3) 收到消息后更新本地配置（如限流配置、接口信息等）；
4) 无需重启应用即可生效。

## 5. 请求处理流程

### 请详细描述一个HTTP请求从进入网关到返回响应的完整流程
1) 请求到达Netty服务器，通过`HttpRequestDecoder`解析为`FullHttpRequest`；
2) 依次经过处理器链：`AuthorizationHandler`(鉴权) → `PreExecutorHandler`(前置处理) → `ExecutorHandler`(服务调用) → `PostExecutorHandler`(后置处理) → `ResultHandler`(结果封装)；
3) 每个处理器通过`ctx.fireChannelRead()`传递给下一个；
4) 最后通过`HttpResponseEncoder`编码响应并返回客户端。

### 请求处理链中各个处理器的执行顺序是什么？
1. `AuthorizationHandler`: 验证JWT令牌和安全组标识
2. `PreExecutorHandler`: 执行自定义前置处理器（限流、黑白名单等）
3. `ExecutorHandler`: 根据协议类型调用HTTP或Dubbo服务
4. `PostExecutorHandler`: 执行自定义后置处理器（日志、监控等）
5. `ResultHandler`: 统一封装响应结果为JSON格式

### 如何实现前置处理器和后置处理器的链式执行？
前置处理器通过`@Order`注解控制执行顺序，按order值从小到大排序执行。支持并行和串行两种模式：

1) 并行处理器通过`CompletableFuture.allOf()`并发执行；

2) 串行处理器通过`thenCompose()`链式执行；

3) 任一处理器返回非null结果则中断链路直接返回响应。

### 如果某个处理器返回了结果，后续处理器还会执行吗？
不会。处理器链采用短路机制：

1) 前置处理器返回非null结果时，立即调用`channel.writeAndFlush()`返回响应，后续处理器不执行；

2) 后置处理器异常不影响主流程，继续执行下一个处理器；

3) 这样可以实现熔断、限流等快速失败机制。

## 6. 请求解析与缓存

### 请解释请求解析的完整流程
1) 从HTTP请求URI中提取接口路径；
2) 先从内存缓存(L1)查询`HttpStatement`对象；
3) 缓存未命中则从Redis(L2)查询接口信息；
4) 根据请求方法(GET/POST/PUT/DELETE)解析参数：GET解析URL参数，POST根据Content-Type解析JSON或表单数据；
5) 进行URL解码和类型转换；
6) 构建`HttpStatement`对象并存入缓存；

7) 传递给后续处理器。

### 为什么采用"双缓存"策略（内存缓存+Redis缓存）？
1) **性能优化**: L1内存缓存访问速度纳秒级，避免频繁访问Redis；
2) **分布式共享**: L2 Redis缓存跨网关节点共享，保证配置一致性；
3) **容错能力**: Redis异常时仍可使用内存缓存；
4) **成本平衡**: 内存缓存容量有限，Redis提供持久化存储。

### 内存缓存和Redis缓存各自的优缺点是什么？
**内存缓存(L1)**：优点-访问速度快(纳秒级)、无网络开销；缺点-容量有限、单机存储、重启丢失。**Redis缓存(L2)**：优点-容量大、分布式共享、持久化；缺点-访问速度慢(毫秒级)、网络开销、需要维护Redis集群。

### 如何保证缓存的一致性？
1) 使用Redis Pub/Sub机制：网关中心修改配置后发布消息到Redis频道；
2) 网关核心监听频道，收到消息后更新内存缓存；
3) 内存缓存采用LFU策略自动淘汰低频数据；
4) 定时清理过期缓存(TTL+空闲时间)；
5) 缓存更新时先更新Redis再更新内存，保证最终一致性。

## 7. 自定义缓存池实现

### 为什么选择LFU（Least Frequently Used）缓存策略而不是LRU？
LFU相比LRU的优势：

1) **保护高频资源**: 频繁访问的接口配置不易被淘汰，保证性能稳定；
2) **适应网关场景**: 网关中某些热点接口访问频率远高于其他接口，LFU能更好地保护这些热点；
3) **长期性能**: LRU易受突发流量影响，LFU通过频率统计更稳定；
4) **缓存命中率**: 在网关高并发场景下，LFU命中率通常比LRU高10-20%。

### LFU缓存的核心数据结构是什么？
1) **cacheMap**: `Map<K, LFUNode<K,V>>`，存储所有缓存节点；
2) **frequencyMap**: `Map<Integer, LinkedHashSet<LFUNode>>`，按频率分组存储节点，便于快速找到最低频率节点；
3) **LFUNode**: 包含key、value、frequency(访问频率)、lastAccessTime(最后访问时间)、createTime(创建时间)等字段；
4) **minFrequency**: 记录当前最小频率，淘汰时直接从该频率组中选择。

### 如何实现缓存的自动淘汰？
1) **容量淘汰**: 缓存满时，找到最小频率的节点，从该频率组中选择最早创建的节点淘汰；
2) **TTL淘汰**: 定时清理线程检查缓存，删除超过TTL(生存时间)的节点；
3) **空闲淘汰**: 删除超过maxIdleTime(最大空闲时间)未被访问的节点；
4) **频率更新**: 每次访问时频率+1，频率变化时更新frequencyMap。

### 定时清空机制的作用是什么？
1) **配置变更适应**: 服务上下线时及时清理过期连接信息；
2) **资源泄露防范**: 防止无效连接积累导致内存溢出；
3) **动态负载均衡**: 清理后重新加载最新配置，适应流量模式变化；
4) **一致性保证**: 定期清理确保内存缓存与Redis缓存保持同步；
5) **性能优化**: 及时释放不再使用的资源，减少GC压力。

## 8. 自定义熔断机制

### 请解释熔断机制的工作原理
熔断机制通过自定义处理器实现：

1) 前置处理器在服务调用前检查是否应该熔断(如限流、黑名单)；
2) 后置处理器在服务调用后检查错误率是否超过阈值；
3) 处理器返回非null结果时立即中断处理链，返回熔断响应；
4) 熔断器有三种状态：CLOSED(正常)、OPEN(熔断)、HALF_OPEN(半开)；
5) 经过一段时间后从OPEN状态转为HALF_OPEN，尝试恢复。

### 前置处理器和后置处理器中的熔断检查有什么区别？
**前置处理器熔断**:

1) 在请求发送前执行，检查系统状态(限流、黑名单等)；
2) 快速失败，避免无谓的服务调用；
3) 保护后端服务不被过载；
4) 例如限流处理器检查QPS是否超过阈值。

**后置处理器熔断**:

1) 在请求返回后执行，检查响应结果(错误率、响应时间等)；
2) 基于实际调用结果判断服务健康度；

3) 用于检测服务故障并自动降级；
3) 例如错误率处理器统计失败次数。

### 如何实现基于QPS的熔断？
1) 在前置处理器中维护计数器`Map<String, AtomicInteger>`；
2) 每个请求到达时计数+1；
3) 定时重置计数器(如每分钟)；
4) 当计数超过阈值(如1000 QPS)时返回熔断结果；
5) 返回HTTP 503状态码和"服务过载"提示；
6) 这样可以快速拒绝超限请求，保护系统。

### 如何实现基于错误率的熔断？
1) 在后置处理器中为每个接口维护`CircuitBreaker`对象；
2) 记录总请求数和失败数；
3) 计算失败率 = 失败数 / 总请求数；
4) 当失败率超过阈值(如50%)且请求数超过最小值(如10)时，熔断器转为OPEN状态；
5) OPEN状态下直接返回熔断响应，不再调用后端服务；
6) 经过超时时间(如30秒)后转为HALF_OPEN，尝试恢复。

## 9. 请求调用与结果包装
- 请描述HTTP和Dubbo两种协议的调用流程
- 如何实现协议的自动路由？
- 为什么采用异步调用而不是同步调用？
- 如何处理异步调用的异常？

## 10. 异步化处理机制

### 异步HTTP执行器是如何实现的？
1. 使用Apache `HttpAsyncClient`替代同步`HttpClient`；
2. 基于NIO的异步网络通信，不阻塞线程；
3. 使用`PoolingAsyncClientConnectionManager`管理异步连接池(最大500连接)；
4. 发送请求时返回`CompletableFuture<HttpResponse>`；
5. 通过`thenApply()`链式处理响应；
6. 异常时通过`exceptionally()`捕获并处理；
7. 支持请求超时控制和连接回收。

### 异步Dubbo调用与同步调用有什么区别？
**同步调用**:

1) 线程阻塞等待服务返回；

2) 占用线程资源，并发能力受限；

3) 简单易用但性能差。**异步调用**:

1) 调用`$invokeAsync()`返回`CompletableFuture`；

2) 线程不阻塞，可继续处理其他请求；

3) 通过`thenApply()`处理结果；

4) 支持超时控制和异常处理；

5) 吞吐量提升3-5倍。

### CompletableFuture在这个项目中的应用场景有哪些？
1) **异步HTTP调用**: 异步发送HTTP请求并处理响应；
1) **异步Dubbo调用**: 异步调用Dubbo服务；
1)  **前置处理器链**: 并行执行多个前置处理器，串行执行需要顺序的处理器；
1) **后置处理器链**: 并行执行所有后置处理器；
1)  **超时控制**: 使用`orTimeout()`设置请求超时；
1)  **异常处理**: 使用`exceptionally()`捕获异常。

### 异步处理相比同步处理的性能提升有多少？
1) **吞吐量**: 异步吞吐量比同步提升3-5倍；
2) **延迟**: 异步平均延迟降低30-50%；
3) **资源利用**: 异步线程利用率提升2-3倍；
4) **并发能力**: 异步可处理数万并发连接，同步仅能处理数百；
5) **实际数据**: 在网关场景下，异步处理QPS可达10万+，同步仅能达到2-3万。

## 11. 分布式限流器

### 请解释多级限流架构的设计思想
采用**本地限流 + Redis分布式限流**的两级架构：

1) **第一层(本地限流)**: 使用Guava RateLimiter，快速拦截大部分超限请求，保护Redis不被打垮；

2) **第二层(Redis限流)**: 使用Lua脚本保证原子性，实现跨网关节点的精确限流控制；

3) **设计理念**: 本地限流承担大部分流量，Redis只处理少量请求，避免Redis成为瓶颈；

4) **异常降级**: Redis异常时自动降级为本地限流，保证系统可用性。

### 本地限流和Redis分布式限流各自的作用是什么？
**本地限流**:

1) 快速失败，无网络开销；

2) 保护Redis不被过载；

3) 承担大部分流量(约80%)；

4) 单机限流，不跨节点。**Redis分布式限流**:

1) 精确控制，跨网关节点协调；

2) 防止多个网关节点总流量超限；

3) 处理少量请求(约20%)；

4) 支持实时配置更新。

### 为什么本地限流器设置为配置值的1.2倍？
1) **留有余量**: 本地限流器设置为1.2倍，给Redis限流器留出空间；

2) **避免过度拦截**: 如果本地限流器设置为1倍，会过度拦截正常请求；

3) **提高吞吐量**: 1.2倍的设置能更好地利用系统容量；

4) **平衡策略**: 本地限流器快速拦截突发流量，Redis限流器精确控制总流量；

5) **实际效果**: 这样设置能将Redis请求量降低到20%左右。

### 令牌桶算法和滑动窗口算法各自适用于什么场景？
**令牌桶算法**:

1) 适用于允许突发流量的场景；

2) 用于全局限流和服务级限流；

3) 以固定速率生成令牌，请求消耗令牌；

4) 优点是能处理突发请求，缺点是可能超过限流阈值。


**滑动窗口算法**:

1) 适用于需要精确控制的场景；

2) 用于接口级限流和IP级限流；

3) 统计时间窗口内的请求数，超过阈值则拒绝；

4) 优点是精确控制，缺点是不能处理突发流量。

## 12. 限流器的四级限流粒度

### 全局限流、服务级限流、接口级限流、IP级限流分别如何实现？
1) **全局限流**: 限流key为"GLOBAL"，限制整个网关集群的总QPS(如10000)；

2) **服务级限流**: 限流key为"SERVICE:{serviceId}"，限制单个后端服务的QPS(如1000)；

3) **接口级限流**: 限流key为"INTERFACE:{serviceId}:{url}"，限制单个接口的QPS(如100)；

4) **IP级限流**: 限流key为"IP:{clientIp}"，限制单个客户端IP的QPS(如50)；

5) 每级限流都通过`DistributedRateLimiter.tryAcquire()`检查，返回false则拒绝请求。

### 多个限流规则同时生效时如何处理？
1) **串行检查**: 在`RateLimitPreHandler`中按顺序检查全局→服务→接口→IP四级限流；

2) **短路机制**: 任一级限流失败则立即返回限流结果，后续级别不再检查；

3) **优先级**: 全局限流优先级最高，IP限流优先级最低；

4) **组合效果**: 多个规则同时生效时，取最严格的限制；

5) **例如**: 全局限流1000 QPS，服务限流500 QPS，则实际限流为500 QPS。

### 如何实现限流配置的实时更新？
1) 网关中心修改限流配置后存储到数据库和Redis；

2) 发布消息到Redis频道"rate-limit-config-update"；

3) 网关核心监听该频道，收到消息后调用`RateLimitConfigListener`；

4) 更新本地限流配置缓存`configCache`；

5) 移除旧的本地限流器，下次访问时重新创建；

6) 无需重启应用，配置立即生效。

### 限流失败时如何返回错误信息？
1) 返回HTTP 429状态码(Too Many Requests)；

2) 返回错误消息如"系统繁忙，请稍后重试"或"访问过于频繁，请稍后重试"；

3) 通过`Result`对象统一封装错误响应；

4) 在`RateLimitPreHandler`中返回非null的Result对象，中断处理链；

5) 最终通过`ResultHandler`将Result转换为HTTP响应返回客户端。

## 13. 限流器的Lua脚本实现

### 为什么使用Lua脚本实现限流而不是Java代码？
1) **原子性保证**: Lua脚本在Redis中原子执行，不会被其他命令中断，避免竞态条件；

2) **网络往返减少**: 一次请求完成多个操作，减少网络开销；

3) **性能提升**: 避免Java代码中的多次Redis调用和网络延迟；

4) **分布式一致性**: 多个网关节点执行同一脚本，结果一致；

5) **实际效果**: 使用Lua脚本的限流性能比Java代码高3-5倍。

### 令牌桶算法的Lua脚本逻辑是什么？
```lua
local key = KEYS[1]
local limit = tonumber(ARGV[1])
local current = tonumber(redis.call('get', key) or '0')
if current < limit then
    redis.call('incr', key)
    if current == 0 then
        redis.call('expire', key, 1)
    end
    return 1
else
    return 0
end
```
逻辑：

1) 获取当前计数；

2) 如果小于限流阈值，计数+1并返回1(允许)；

3) 首次计数时设置1秒过期；

4) 否则返回0(拒绝)。

### 滑动窗口算法的Lua脚本逻辑是什么？
```lua
local key = KEYS[1]
local limit = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local current = tonumber(ARGV[3])
local expire_time = current - window * 1000
redis.call('zremrangebyscore', key, 0, expire_time)
local count = redis.call('zcard', key)
if count < limit then
    redis.call('zadd', key, current, current)
    redis.call('expire', key, window + 1)
    return 1
else
    return 0
end
```
逻辑：

1) 删除过期数据(时间戳小于窗口起点)；

2) 统计窗口内请求数；

3) 如果小于限流阈值，添加当前请求并返回1；

4) 否则返回0。

### 如何保证Lua脚本的原子性？
1) **Redis单线程**: Redis本身是单线程的，Lua脚本在Redis中原子执行；

2) **EVAL命令**: 使用`EVAL`命令执行脚本，Redis保证脚本执行期间不会执行其他命令；

3) **无中断**: 脚本执行过程中不会被其他客户端的请求中断；

4) **事务性**: 脚本内的所有操作要么全部成功，要么全部失败；

5) **分布式安全**: 多个网关节点同时执行脚本，Redis保证结果一致。

## 14. 限流器的异常降级

### Redis异常时如何降级处理？
1) 在`DistributedRateLimiter.tryAcquire()`中使用try-catch捕获异常；

2) 异常时调用`tryAcquireLocal()`只使用本地限流；

3) 记录详细的错误日志便于问题排查；

4) 返回本地限流的结果，保证系统可用性；

5) 不抛出异常，避免影响正常业务。

### 降级后的限流效果如何？
1) **精度下降**: 从分布式精确限流降级为本地限流，多个网关节点的总流量可能超过配置值；

2) **保护能力减弱**: 无法跨节点协调，单个节点可能过载；

3) **可接受范围**: 通常在可接受范围内，因为本地限流器设置为1.2倍，有一定的容错空间；

4) **临时方案**: 降级是临时方案，Redis恢复后自动恢复到分布式限流。

### 如何监控降级事件？
1) 在异常捕获处记录ERROR级别日志，包含异常堆栈；

2) 可集成监控系统(如Prometheus)，统计降级次数；

3) 设置告警规则，降级事件超过阈值时告警；

4) 定期检查日志，分析降级原因；

5) 记录降级时间、持续时间等信息，便于事后分析。

### 降级恢复的条件是什么？
1) **自动恢复**: 当Redis恢复正常时，下一次限流检查会自动使用Redis限流；

2) **无需重启**: 无需重启应用，自动恢复；

3) **恢复时机**: 当`tryAcquireDistributed()`成功执行时，说明Redis已恢复；

4) **平滑过渡**: 恢复过程平滑，不会对业务造成影响；

5) **监控确认**: 通过监控系统确认Redis已恢复，降级事件停止。

